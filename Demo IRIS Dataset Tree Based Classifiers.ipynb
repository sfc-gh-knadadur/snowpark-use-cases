{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42460e1-60de-4ef0-97a5-9c6398e395f6",
   "metadata": {},
   "source": [
    "### Load Snowpark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5bd4557-d428-494b-8b92-9c74e417e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowflake snowpark version is: (0, 10, 0)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import avg, sum, col,lit\n",
    "from snowflake.snowpark.functions import udf, sproc, col\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, LongType, DoubleType, DecimalType,StringType, BooleanType, Variant\n",
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "from snowflake.snowpark import functions as fn\n",
    "\n",
    "import sys ,json\n",
    "import io\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from snowflake.snowpark import version\n",
    "print (f\"snowflake snowpark version is: {version.VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a80ae1-2be8-45ff-bf2e-e46918e944ee",
   "metadata": {},
   "source": [
    "### Connect to Snowflake and establish session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf3189c-5b46-4b30-bd01-58cdc75717da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Database: \"BANK1_CRM_DB\"\n",
      "Current Schema: \"PUBLIC\"\n",
      "Current Warehouse: \"APP_WH\"\n"
     ]
    }
   ],
   "source": [
    "snowflake_connection_cfg = open('cred.json')\n",
    "snowflake_connection_cfg = snowflake_connection_cfg.read()\n",
    "snowflake_connection_cfg = json.loads(snowflake_connection_cfg)\n",
    "\n",
    "# Creating Snowpark Session\n",
    "rf_session = Session.builder.configs(snowflake_connection_cfg).create()\n",
    "print('Current Database:', rf_session.get_current_database())\n",
    "print('Current Schema:', rf_session.get_current_schema())\n",
    "print('Current Warehouse:', rf_session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f9861-440b-4eba-973d-31ddd32ab497",
   "metadata": {},
   "source": [
    "### Create stage location for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ca3d6a-67d0-44f9-b3d9-9ba62683e7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area STAGE_MODELS successfully created.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_session.sql(\"CREATE OR REPLACE STAGE stage_models\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a72055-cf43-4b2a-8ca8-edce6b4fd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_session.clear_packages()\n",
    "rf_session.add_packages(\"snowflake-snowpark-python\")\n",
    "rf_session.add_packages(\"scikit-learn\",\"pandas\",\"numpy\",\"joblib\",\"cachetools\")\n",
    "rf_session.clear_imports()\n",
    "# rf_session.add_import(ge_import_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a408a-8714-4888-aed6-dc0239fc91fb",
   "metadata": {},
   "source": [
    "### Define function to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3e1b08-20fa-4ec9-829f-feb1c47abe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(session, model, path, dest_filename):\n",
    "    # logger.debug('#save_file: -- START--')\n",
    "    input_stream = io.BytesIO()\n",
    "    joblib.dump(model, input_stream)\n",
    "    session._conn.upload_stream(input_stream, path, dest_filename)\n",
    "    return \"successfully created file: \" + path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfead7a3-0159-405a-9af1-084c44b551a2",
   "metadata": {},
   "source": [
    "### Define Features required to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c3a64bd-4c22-4ce6-9e51-0d0a513c652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['SEPTAL_LENGTH','SEPTAL_WIDTH','PETAL_LENGTH','PETAL_WIDTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba43c98-3092-4cb7-87cb-488d06c0276e",
   "metadata": {},
   "source": [
    "### Define Model pipeline for Imputer, Standard Scaler and Random Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1a7471-4baa-4264-907b-cf1bd366efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rf_model(p_df: pd.DataFrame,ne,nj,cw, md):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    numeric_features = p_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = p_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    feature_names = numeric_features + categorical_features\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler(with_mean=True,with_std=True))])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier'\n",
    "                    ,RandomForestClassifier(n_estimators=ne, n_jobs=-nj, class_weight=cw,max_depth=md)\n",
    "                    # ,RandomForestClassifier(n_estimators=4, n_jobs=-1, class_weight='balanced_subsample',max_depth=20)\n",
    "                    # ,RandomForestClassifier(maxBins=20,featureSubsetStrategy='onethird') need to find the equivalents\n",
    "                    # of these maxBins and featureSubsetStrategy. For featureSubsetStrategy I do think it is the \n",
    "                    # classweight from sklearn based on the documentation. I also think maxBins could be the same as\n",
    "                    # maxdepth.\n",
    "                )\n",
    "            ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a945f889-f5b3-4f20-a3c0-1a222da635f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dtree_model(p_df: pd.DataFrame,cw, md):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    numeric_features = p_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = p_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    feature_names = numeric_features + categorical_features\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler(with_mean=True,with_std=True))])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier'\n",
    "                    ,DecisionTreeClassifier(class_weight=cw,max_depth=md)\n",
    "                    # ,RandomForestClassifier(n_estimators=4, n_jobs=-1, class_weight='balanced_subsample',max_depth=20)\n",
    "                    # ,RandomForestClassifier(maxBins=20,featureSubsetStrategy='onethird') need to find the equivalents\n",
    "                    # of these maxBins and featureSubsetStrategy. For featureSubsetStrategy I do think it is the \n",
    "                    # classweight from sklearn based on the documentation. I also think maxBins could be the same as\n",
    "                    # maxdepth.\n",
    "                )\n",
    "            ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a1f3d-efcb-4bf0-86b9-eefc8b98c98b",
   "metadata": {},
   "source": [
    "### Define Classification report to register model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849cb0ab-9421-47ac-bd0f-b0fc2037ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    from sklearn import metrics\n",
    "    report = metrics.classification_report(y_test, y_pred, output_dict=True,target_names=['setosa', 'versicolor', 'virginica'])\n",
    "    df_classification_report = pd.DataFrame(report).transpose()    \n",
    "    return df_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a819bdd-f1c2-417d-9cb2-db7ffc9a55d9",
   "metadata": {},
   "source": [
    "### Define Model parameteres to register model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4802883-d0ef-42ed-a7db-5c33baec86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_info(model_name, test_size, random_state,ne,nj,cw,max_depth):\n",
    "    data = [[model_name,test_size,random_state,ne,nj,cw,max_depth]]  \n",
    "    df_model_info = pd.DataFrame(data,columns=['model','test_size','random_state','ne','nj','cw','max_depth'])\n",
    "    return df_model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fab21-0f9b-426e-a844-b22c51285c9e",
   "metadata": {},
   "source": [
    "### Define Train random forest classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9300bc8-2de4-409c-b45e-c47f3a192681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf_model(session: Session, training_table: str, sample_size_n: int, model_name: str,features:list, Y: str,test_size:float,random_state:int,ne:int,nj:int,cw:str, md:int) -> str:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "    training_data = session.table(training_table).sample(n=sample_size_n)\n",
    "    Data_train, Data_test = training_data.random_split([1-test_size, test_size], seed=random_state)\n",
    "    pd_Data_train=Data_train.to_pandas()\n",
    "    pd_Data_test=Data_test.to_pandas()\n",
    "    from sklearn.ensemble import RandomForestClassifier \n",
    "    # Model building\n",
    "    rf = build_rf_model(pd_Data_train[features],ne,nj,cw, md)\n",
    "    rf.fit(pd_Data_train[features], pd_Data_train[Y])\n",
    "\n",
    "    model_dir = '@stage_models'\n",
    "    model_fl = model_name+'.joblib'\n",
    "    save_file(session, rf, model_dir ,model_fl)\n",
    "\n",
    "    score = rf.score(pd_Data_test[features], pd_Data_test[Y])\n",
    "    \n",
    "    y_pred = rf.predict(pd_Data_test)\n",
    "    df_classification_report = get_classification_report(y_pred,pd_Data_test[Y]).reset_index().rename(columns={\"index\": \"class\"}).reset_index(drop=True)\n",
    "    df_model_info = get_model_info(model_fl,test_size,random_state,ne,nj,cw,md)\n",
    "    df_model_info=df_model_info.append([df_model_info]*5,ignore_index=True)\n",
    "    session.create_dataframe(df_classification_report.join(df_model_info)).write.mode(\"append\").save_as_table(\"model_output\")\n",
    "    \n",
    "    return df_classification_report.join(df_model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646a71d-c857-41ac-81d8-bc590b3d9447",
   "metadata": {},
   "source": [
    "### Define train decision Tree classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fab2d5b-63fd-45a1-a568-21d3b9d4c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dtree_model(session: Session, training_table: str, sample_size_n: int, model_name: str,features:list, Y: str,test_size:float,random_state:int,cw:str, md:int) -> str:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "    training_data = session.table(training_table).sample(n=sample_size_n)\n",
    "    Data_train, Data_test = training_data.random_split([1-test_size, test_size], seed=random_state)\n",
    "    pd_Data_train=Data_train.to_pandas()\n",
    "    pd_Data_test=Data_test.to_pandas()\n",
    "    from sklearn.ensemble import RandomForestClassifier \n",
    "    # Model building\n",
    "    dtree = build_dtree_model(pd_Data_train[features],cw, md)\n",
    "    dtree.fit(pd_Data_train[features], pd_Data_train[Y])\n",
    "\n",
    "    model_dir = '@stage_models'\n",
    "    model_fl = model_name+'.joblib'\n",
    "    save_file(session, dtree, model_dir ,model_fl)\n",
    "\n",
    "    score = dtree.score(pd_Data_test[features], pd_Data_test[Y])\n",
    "    \n",
    "    y_pred = dtree.predict(pd_Data_test)\n",
    "    df_classification_report = get_classification_report(y_pred,pd_Data_test[Y]).reset_index().rename(columns={\"index\": \"class\"}).reset_index(drop=True)\n",
    "    df_model_info = get_model_info(model_fl,test_size,random_state,None,None,cw,md)\n",
    "    df_model_info=df_model_info.append([df_model_info]*5,ignore_index=True)\n",
    "    session.create_dataframe(df_classification_report.join(df_model_info)).write.mode(\"append\").save_as_table(\"model_output\")\n",
    "    \n",
    "    return df_classification_report.join(df_model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986ecb2-8721-4a1b-84e4-adeb4840d409",
   "metadata": {},
   "source": [
    "### Create Model output tables to save model ouptut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc162bb8-ccb4-4378-972a-ab5dca3ddd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Table MODEL_OUTPUT successfully created.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_session.sql(\"create or replace table model_output (class varchar, precision double, recall double, f1score double, support double, model varchar,test_size float, random_state int, ne int, nj int, cw varchar, max_depth int)\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4f52f-80c1-4584-96fb-22ecfedd4ed4",
   "metadata": {},
   "source": [
    "### Define stored proc to register random forest classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344bd301-3b29-4590-a828-ae4c38cf5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering the function as a Stored Procedure\n",
    "rf_sproc = rf_session.sproc.register(func=train_rf_model, # training function defined above\n",
    "                                            name='train_rf_model', # training model name to be registered in snowlake\n",
    "                                            is_permanent=True, # permanent stored proc\n",
    "                                            replace=True, # replace if existing already\n",
    "                                            stage_location='@stage_models', # save the model in stage location\n",
    "                                            packages=['snowflake-snowpark-python','scikit-learn','joblib']) # import model libaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3632e9-7132-44ff-a946-b1dd50bc6e7e",
   "metadata": {},
   "source": [
    "### Define Stored Proc to register decision tree classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87dc43c2-a330-4fa5-bca6-5b72bc34ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering the function as a Stored Procedure\n",
    "dtree_sproc = rf_session.sproc.register(func=train_dtree_model, # training function defined above\n",
    "                                            name='train_dtree_model', # training model name to be registered in snowlake\n",
    "                                            is_permanent=True, # permanent stored proc\n",
    "                                            replace=True, # replace if existing already\n",
    "                                            stage_location='@stage_models', # save the model in stage location\n",
    "                                            packages=['snowflake-snowpark-python','scikit-learn','joblib']) # import model libaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b9ab8-9d16-4d33-9588-aad06f7efcd9",
   "metadata": {},
   "source": [
    "### Train  Random Forest classifier and Decision Tree Classifier in Snowflake through registered Stored Procs and capture model output in a snowflake table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deea381-4ec7-42d6-a4ff-aedec6e955d0",
   "metadata": {},
   "source": [
    "### All the above steps are just definition and Registration of component\n",
    "### The below training runs completely on Snowflake and you can go check in history tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88fd5c12-92bf-4004-b104-4c11b8931f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest classifier report\n",
      "          class  precision  recall  ...  nj                  cw max_depth\n",
      "0        setosa        1.0     1.0  ...   1  balanced_subsample        15\n",
      "1    versicolor        1.0     1.0  ...   1  balanced_subsample        15\n",
      "2     virginica        1.0     1.0  ...   1  balanced_subsample        15\n",
      "3      accuracy        1.0     1.0  ...   1  balanced_subsample        15\n",
      "4     macro avg        1.0     1.0  ...   1  balanced_subsample        15\n",
      "5  weighted avg        1.0     1.0  ...   1  balanced_subsample        15\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 100,\n",
    "test_size = 0.1\n",
    "max_depth = 15\n",
    "model_name = 'rf_iris_model'\n",
    "random_state = 43,\n",
    "n_estimator = 4\n",
    "n_jobs = 1,\n",
    "class_weight = 'balanced_subsample'\n",
    "print (\"random forest classifier report\")\n",
    "print (rf_sproc(table_name\n",
    "                ,150\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43\n",
    "                ,n_estimator\n",
    "                ,1\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a236052-8026-44ed-a451-5916c7feb8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest classifier report\n",
      "          class  precision  recall  ...  nj                  cw max_depth\n",
      "0        setosa        1.0     1.0  ...   1  balanced_subsample        15\n",
      "1    versicolor        1.0     1.0  ...   1  balanced_subsample        15\n",
      "2     virginica        1.0     1.0  ...   1  balanced_subsample        15\n",
      "3      accuracy        1.0     1.0  ...   1  balanced_subsample        15\n",
      "4     macro avg        1.0     1.0  ...   1  balanced_subsample        15\n",
      "5  weighted avg        1.0     1.0  ...   1  balanced_subsample        15\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 100,\n",
    "test_size = 0.1\n",
    "max_depth = 15\n",
    "model_name = 'rf_iris_model_'+'ts'+str(test_size)+'_'+'md'+str(max_depth)\n",
    "random_state = 43,\n",
    "n_estimator = 4\n",
    "n_jobs = 1,\n",
    "class_weight = 'balanced_subsample'\n",
    "print (\"random forest classifier report\")\n",
    "print (rf_sproc(table_name\n",
    "                ,150\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43\n",
    "                ,n_estimator\n",
    "                ,1\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd48da1-a25a-4c0e-b27d-0bd67deaa525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest classifier report\n",
      "          class  precision    recall  ...  nj                  cw max_depth\n",
      "0        setosa   1.000000  1.000000  ...   1  balanced_subsample        20\n",
      "1    versicolor   0.900000  0.900000  ...   1  balanced_subsample        20\n",
      "2     virginica   0.875000  0.875000  ...   1  balanced_subsample        20\n",
      "3      accuracy   0.925926  0.925926  ...   1  balanced_subsample        20\n",
      "4     macro avg   0.925000  0.925000  ...   1  balanced_subsample        20\n",
      "5  weighted avg   0.925926  0.925926  ...   1  balanced_subsample        20\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 150,\n",
    "test_size = 0.25\n",
    "max_depth = 20\n",
    "model_name = 'rf_iris_model_'+'ts'+str(test_size)+'_'+'md'+str(max_depth)\n",
    "random_state = 43,\n",
    "n_estimator = 4\n",
    "n_jobs = 1,\n",
    "class_weight = 'balanced_subsample'\n",
    "print (\"random forest classifier report\")\n",
    "print (rf_sproc(table_name\n",
    "                ,100\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43\n",
    "                ,n_estimator\n",
    "                ,1\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f85586b-3823-4c12-8e76-fb7bd0cf8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest classifier report\n",
      "          class  precision    recall  ...  nj                  cw max_depth\n",
      "0        setosa   1.000000  1.000000  ...   1  balanced_subsample        25\n",
      "1    versicolor   0.833333  0.909091  ...   1  balanced_subsample        25\n",
      "2     virginica   0.800000  0.666667  ...   1  balanced_subsample        25\n",
      "3      accuracy   0.888889  0.888889  ...   1  balanced_subsample        25\n",
      "4     macro avg   0.877778  0.858586  ...   1  balanced_subsample        25\n",
      "5  weighted avg   0.887654  0.888889  ...   1  balanced_subsample        25\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 150,\n",
    "test_size = 0.25\n",
    "max_depth = 25\n",
    "model_name = 'rf_iris_model_'+'ts'+str(test_size)+'_'+'md'+str(max_depth)\n",
    "random_state = 43,\n",
    "n_estimator = 4\n",
    "n_jobs = 1,\n",
    "class_weight = 'balanced_subsample'\n",
    "print (\"random forest classifier report\")\n",
    "print (rf_sproc(table_name\n",
    "                ,100\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43\n",
    "                ,n_estimator\n",
    "                ,1\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84a6027e-d22e-4259-8ddc-5900b8b27945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier report\n",
      "          class  precision    recall  f1-score  ...  ne nj        cw  max_depth\n",
      "0        setosa   1.000000  1.000000  1.000000  ...   4  1  balanced         20\n",
      "1    versicolor   0.857143  1.000000  0.923077  ...   4  1  balanced         20\n",
      "2     virginica   1.000000  0.777778  0.875000  ...   4  1  balanced         20\n",
      "3      accuracy   0.941176  0.941176  0.941176  ...   4  1  balanced         20\n",
      "4     macro avg   0.952381  0.925926  0.932692  ...   4  1  balanced         20\n",
      "5  weighted avg   0.949580  0.941176  0.939762  ...   4  1  balanced         20\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 150,\n",
    "test_size = 0.25\n",
    "max_depth = 20\n",
    "model_name = 'dtree_iris_model'\n",
    "random_state = 43,\n",
    "class_weight = 'balanced'\n",
    "print (\"decision tree classifier report\")\n",
    "print (rf_sproc(table_name\n",
    "                ,150\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43,\n",
    "                4,\n",
    "                1\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc4aa79-88be-4254-bb05-165b1944eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier report\n",
      "          class  precision    recall  f1-score  ...  ne nj        cw  max_depth\n",
      "0        setosa   1.000000  1.000000  1.000000  ...   4  1  balanced         20\n",
      "1    versicolor   0.928571  1.000000  0.962963  ...   4  1  balanced         20\n",
      "2     virginica   1.000000  0.875000  0.933333  ...   4  1  balanced         20\n",
      "3      accuracy   0.970588  0.970588  0.970588  ...   4  1  balanced         20\n",
      "4     macro avg   0.976190  0.958333  0.965432  ...   4  1  balanced         20\n",
      "5  weighted avg   0.972689  0.970588  0.970153  ...   4  1  balanced         20\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 150,\n",
    "test_size = 0.25\n",
    "max_depth = 20\n",
    "model_name = 'dtree_iris_model_'+'ts'+str(test_size)+'_'+'md'+str(max_depth)\n",
    "random_state = 43,\n",
    "class_weight = 'balanced'\n",
    "print (\"decision tree classifier report\")\n",
    "print (rf_sproc(table_name\n",
    "                ,150\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43,\n",
    "                4,\n",
    "                1\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f024852-594f-413d-887d-4e5a2433dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier report\n",
      "          class  precision    recall  f1-score  ...    ne    nj        cw  max_depth\n",
      "0        setosa   1.000000  1.000000  1.000000  ...  None  None  balanced         25\n",
      "1    versicolor   0.750000  0.750000  0.750000  ...  None  None  balanced         25\n",
      "2     virginica   0.857143  0.857143  0.857143  ...  None  None  balanced         25\n",
      "3      accuracy   0.851852  0.851852  0.851852  ...  None  None  balanced         25\n",
      "4     macro avg   0.869048  0.869048  0.869048  ...  None  None  balanced         25\n",
      "5  weighted avg   0.851852  0.851852  0.851852  ...  None  None  balanced         25\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 100,\n",
    "test_size = 0.25\n",
    "max_depth = 25\n",
    "model_name = 'dtree_iris_model_'+'ts'+str(test_size)+'_'+'md'+str(max_depth)\n",
    "random_state = 43,\n",
    "class_weight = 'balanced'\n",
    "print (\"decision tree classifier report\")\n",
    "print (dtree_sproc(table_name\n",
    "                ,100\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71ca9165-98b9-4442-ae54-4a829c456442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier report\n",
      "          class  precision    recall  f1-score  ...    ne    nj        cw  max_depth\n",
      "0        setosa   1.000000  1.000000  1.000000  ...  None  None  balanced         30\n",
      "1    versicolor   0.900000  1.000000  0.947368  ...  None  None  balanced         30\n",
      "2     virginica   1.000000  0.909091  0.952381  ...  None  None  balanced         30\n",
      "3      accuracy   0.962963  0.962963  0.962963  ...  None  None  balanced         30\n",
      "4     macro avg   0.966667  0.969697  0.966583  ...  None  None  balanced         30\n",
      "5  weighted avg   0.966667  0.962963  0.963056  ...  None  None  balanced         30\n",
      "\n",
      "[6 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "table_name = 'iris_dataset'\n",
    "sample = 100,\n",
    "test_size = 0.25\n",
    "max_depth = 30\n",
    "model_name = 'dtree_iris_model_'+'ts'+str(test_size)+'_'+'md'+str(max_depth)\n",
    "random_state = 43,\n",
    "class_weight = 'balanced'\n",
    "print (\"decision tree classifier report\")\n",
    "print (dtree_sproc(table_name\n",
    "                ,100\n",
    "                , model_name\n",
    "                ,features\n",
    "                ,'LABEL'\n",
    "                ,test_size\n",
    "                ,43\n",
    "                ,class_weight\n",
    "                , max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19dc9c21-486e-4405-a9dc-5652235ec40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "|\"CLASS\"       |\"PRECISION\"  |\"RECALL\"  |\"F1SCORE\"  |\"MODEL\"                              |\"TEST_SIZE\"  |\"MAX_DEPTH\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "|weighted avg  |1.0          |1.0       |1.0        |rf_iris_model.joblib                 |0.1          |15           |\n",
      "|setosa        |1.0          |1.0       |1.0        |dtree_iris_model_ts0.25_md20.joblib  |0.25         |20           |\n",
      "|setosa        |1.0          |1.0       |1.0        |rf_iris_model_ts0.1_md15.joblib      |0.1          |15           |\n",
      "|setosa        |1.0          |1.0       |1.0        |rf_iris_model.joblib                 |0.1          |15           |\n",
      "|versicolor    |1.0          |1.0       |1.0        |rf_iris_model.joblib                 |0.1          |15           |\n",
      "|virginica     |1.0          |1.0       |1.0        |rf_iris_model.joblib                 |0.1          |15           |\n",
      "|setosa        |1.0          |1.0       |1.0        |rf_iris_model_ts0.25_md25.joblib     |0.25         |25           |\n",
      "|accuracy      |1.0          |1.0       |1.0        |rf_iris_model.joblib                 |0.1          |15           |\n",
      "|macro avg     |1.0          |1.0       |1.0        |rf_iris_model.joblib                 |0.1          |15           |\n",
      "|setosa        |1.0          |1.0       |1.0        |dtree_iris_model_ts0.25_md25.joblib  |0.25         |25           |\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_session.sql(\"\"\"select class,precision,recall,f1score,model,test_size,max_depth from model_output \n",
    "               order by f1score desc\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6f039-5a42-414f-bcb8-5962a0915d54",
   "metadata": {},
   "source": [
    "### Check if the classifier models are saved in stage location.\n",
    "### Remember if the same model name was used for all the iterations, then only the last trained model will be saved\n",
    "### for the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2067e1fd-60e6-462b-a0bb-9f44688b1e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='stage_models/dtree_iris_model.joblib', size=9760, md5='93176d7bb0c3ad50081521a5c8f0af68', last_modified='Mon, 28 Nov 2022 07:03:39 GMT'),\n",
       " Row(name='stage_models/dtree_iris_model_ts0.25_md20.joblib', size=9920, md5='6f6838af74d27b27041cc7174ee615dc', last_modified='Mon, 28 Nov 2022 06:59:14 GMT'),\n",
       " Row(name='stage_models/dtree_iris_model_ts0.25_md25.joblib', size=4304, md5='a3a907bf4bcf144fbf5e443f158397fb', last_modified='Mon, 28 Nov 2022 07:00:57 GMT'),\n",
       " Row(name='stage_models/dtree_iris_model_ts0.25_md30.joblib', size=4624, md5='52ba383dae0c431af809f6a38b3efd5a', last_modified='Mon, 28 Nov 2022 07:01:30 GMT'),\n",
       " Row(name='stage_models/rf_iris_model.joblib', size=10416, md5='0322dabbe9898ed39b8b2caebbd67b23', last_modified='Mon, 28 Nov 2022 07:02:05 GMT'),\n",
       " Row(name='stage_models/rf_iris_model_ts0.1_md15.joblib', size=10256, md5='44ece3e89482d80f09f45a6a877eb2d6', last_modified='Mon, 28 Nov 2022 07:01:57 GMT'),\n",
       " Row(name='stage_models/rf_iris_model_ts0.25_md20.joblib', size=8496, md5='a228b46fb6212622d75d8abb78ac3b53', last_modified='Mon, 28 Nov 2022 06:59:00 GMT'),\n",
       " Row(name='stage_models/rf_iris_model_ts0.25_md25.joblib', size=8976, md5='9a5f7f64a93dc5e6a3d9edf0a674a07c', last_modified='Mon, 28 Nov 2022 06:59:07 GMT')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_session.sql(\"list @stage_models\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf550172-af3e-4297-a374-698d70a2603c",
   "metadata": {},
   "source": [
    "### Define UDF for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600a84e-2fd5-42d3-92c3-a489c30d10ee",
   "metadata": {},
   "source": [
    "### for Randomforest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46baebe4-92db-4b26-a754-3bd1ee13f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cachetools\n",
    "import os\n",
    "from snowflake.snowpark.functions import udf\n",
    "rf_session.add_import(\"@stage_models/rf_iris_model.joblib\")  \n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "@udf(name=\"predict_rf_iris_model\", is_permanent=True, stage_location=\"@stage_models\", replace=True)\n",
    "def predict(SEPTAL_LENGTH: float, SEPTAL_WIDTH: float, PETAL_LENGTH: float, PETAL_WIDTH: float) -> float:\n",
    "       m = read_file('rf_iris_model.joblib')       \n",
    "       row = pd.DataFrame([locals()], columns=features)\n",
    "       return m.predict(row)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b235f-c3fa-4967-8075-442cbc9469ed",
   "metadata": {},
   "source": [
    "### for Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1b4f735-c6a5-49c4-ab42-deec1ae09286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cachetools\n",
    "import os\n",
    "from snowflake.snowpark.functions import udf\n",
    "rf_session.add_import(\"@stage_models/dtree_iris_model.joblib\")  \n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "@udf(name=\"predict_dtree_iris_model\", is_permanent=True, stage_location=\"@stage_models\", replace=True)\n",
    "def predict(SEPTAL_LENGTH: float, SEPTAL_WIDTH: float, PETAL_LENGTH: float, PETAL_WIDTH: float) -> float:\n",
    "       m = read_file('dtree_iris_model.joblib')       \n",
    "       row = pd.DataFrame([locals()], columns=features)\n",
    "       return m.predict(row)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68940677-8fb5-477f-806f-fa37ac39a9f0",
   "metadata": {},
   "source": [
    "### Load Dataset to snowflake table for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f85c86-e850-4531-a322-39d802dd5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "data = load_iris()\n",
    "cols = ['SEPTAL_LENGTH','SEPTAL_WIDTH','PETAL_LENGTH','PETAL_WIDTH']\n",
    "df = pd.DataFrame(data=data.data, columns=cols)\n",
    "df['LABEL'] = data.target\n",
    "rf_session.create_dataframe(df).write.mode(\"overwrite\").save_as_table(\"iris_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ad9b2-831f-4ce4-9289-f76cf1b51ea7",
   "metadata": {},
   "source": [
    "### Check sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcde6d6c-2570-4535-8718-d73e796bba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "|\"SEPTAL_LENGTH\"  |\"SEPTAL_WIDTH\"  |\"PETAL_LENGTH\"  |\"PETAL_WIDTH\"  |\"LABEL\"  |\n",
      "-------------------------------------------------------------------------------\n",
      "|5.1              |3.5             |1.4             |0.2            |0        |\n",
      "|4.9              |3.0             |1.4             |0.2            |0        |\n",
      "|4.7              |3.2             |1.3             |0.2            |0        |\n",
      "|4.6              |3.1             |1.5             |0.2            |0        |\n",
      "|5.0              |3.6             |1.4             |0.2            |0        |\n",
      "|5.4              |3.9             |1.7             |0.4            |0        |\n",
      "|4.6              |3.4             |1.4             |0.3            |0        |\n",
      "|5.0              |3.4             |1.5             |0.2            |0        |\n",
      "|4.4              |2.9             |1.4             |0.2            |0        |\n",
      "|4.9              |3.1             |1.5             |0.1            |0        |\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snowpark_iris_df = rf_session.table('iris_dataset')\n",
    "snowpark_iris_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700e9e6-107f-4516-ae8b-30e1abe72b96",
   "metadata": {},
   "source": [
    "### Check Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef40d0e6-a59f-4f00-b8e0-d8c0d36c8b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('SEPTAL_LENGTH', DoubleType(), nullable=True),\n",
       " StructField('SEPTAL_WIDTH', DoubleType(), nullable=True),\n",
       " StructField('PETAL_LENGTH', DoubleType(), nullable=True),\n",
       " StructField('PETAL_WIDTH', DoubleType(), nullable=True),\n",
       " StructField('LABEL', LongType(), nullable=True)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowpark_iris_df.schema.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580408c-f8a0-4238-aa39-94e24dc7d1ec",
   "metadata": {},
   "source": [
    "### Now using both randomforest and decisiontree classifiers let's predict and infer using SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c436f3-dd8d-4509-bbde-198835bd70fb",
   "metadata": {},
   "source": [
    "### You can compare both model inference results side by side using SQL Query completed run on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e679663c-0368-4689-9a0c-b88fa1bc0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "|\"ACTUAL_LABEL\"  |\"PRED_RF_LABEL\"  |\"PRED_DTREE_LABEL\"  |\"SEPTAL_LENGTH\"  |\"SEPTAL_WIDTH\"  |\"PETAL_LENGTH\"  |\"PETAL_WIDTH\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "|0               |0.0              |0.0                 |5.1              |3.5             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.9              |3.0             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.7              |3.2             |1.3             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.6              |3.1             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.6             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.4              |3.9             |1.7             |0.4            |\n",
      "|0               |0.0              |0.0                 |4.6              |3.4             |1.4             |0.3            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.4             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.4              |2.9             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.9              |3.1             |1.5             |0.1            |\n",
      "|0               |0.0              |0.0                 |5.4              |3.7             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.8              |3.4             |1.6             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.8              |3.0             |1.4             |0.1            |\n",
      "|0               |0.0              |0.0                 |4.3              |3.0             |1.1             |0.1            |\n",
      "|0               |0.0              |0.0                 |5.8              |4.0             |1.2             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.7              |4.4             |1.5             |0.4            |\n",
      "|0               |0.0              |0.0                 |5.4              |3.9             |1.3             |0.4            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.5             |1.4             |0.3            |\n",
      "|0               |0.0              |0.0                 |5.7              |3.8             |1.7             |0.3            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.8             |1.5             |0.3            |\n",
      "|0               |0.0              |0.0                 |5.4              |3.4             |1.7             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.7             |1.5             |0.4            |\n",
      "|0               |0.0              |0.0                 |4.6              |3.6             |1.0             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.3             |1.7             |0.5            |\n",
      "|0               |0.0              |0.0                 |4.8              |3.4             |1.9             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.0             |1.6             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.4             |1.6             |0.4            |\n",
      "|0               |0.0              |0.0                 |5.2              |3.5             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.2              |3.4             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.7              |3.2             |1.6             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.8              |3.1             |1.6             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.4              |3.4             |1.5             |0.4            |\n",
      "|0               |0.0              |0.0                 |5.2              |4.1             |1.5             |0.1            |\n",
      "|0               |0.0              |0.0                 |5.5              |4.2             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.9              |3.1             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.2             |1.2             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.5              |3.5             |1.3             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.9              |3.6             |1.4             |0.1            |\n",
      "|0               |0.0              |0.0                 |4.4              |3.0             |1.3             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.4             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.5             |1.3             |0.3            |\n",
      "|0               |0.0              |0.0                 |4.5              |2.3             |1.3             |0.3            |\n",
      "|0               |0.0              |0.0                 |4.4              |3.2             |1.3             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.5             |1.6             |0.6            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.8             |1.9             |0.4            |\n",
      "|0               |0.0              |0.0                 |4.8              |3.0             |1.4             |0.3            |\n",
      "|0               |0.0              |0.0                 |5.1              |3.8             |1.6             |0.2            |\n",
      "|0               |0.0              |0.0                 |4.6              |3.2             |1.4             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.3              |3.7             |1.5             |0.2            |\n",
      "|0               |0.0              |0.0                 |5.0              |3.3             |1.4             |0.2            |\n",
      "|1               |1.0              |1.0                 |7.0              |3.2             |4.7             |1.4            |\n",
      "|1               |1.0              |1.0                 |6.4              |3.2             |4.5             |1.5            |\n",
      "|1               |1.0              |1.0                 |6.9              |3.1             |4.9             |1.5            |\n",
      "|1               |1.0              |1.0                 |5.5              |2.3             |4.0             |1.3            |\n",
      "|1               |1.0              |1.0                 |6.5              |2.8             |4.6             |1.5            |\n",
      "|1               |1.0              |1.0                 |5.7              |2.8             |4.5             |1.3            |\n",
      "|1               |1.0              |1.0                 |6.3              |3.3             |4.7             |1.6            |\n",
      "|1               |1.0              |1.0                 |4.9              |2.4             |3.3             |1.0            |\n",
      "|1               |1.0              |1.0                 |6.6              |2.9             |4.6             |1.3            |\n",
      "|1               |1.0              |1.0                 |5.2              |2.7             |3.9             |1.4            |\n",
      "|1               |1.0              |1.0                 |5.0              |2.0             |3.5             |1.0            |\n",
      "|1               |1.0              |1.0                 |5.9              |3.0             |4.2             |1.5            |\n",
      "|1               |1.0              |1.0                 |6.0              |2.2             |4.0             |1.0            |\n",
      "|1               |1.0              |1.0                 |6.1              |2.9             |4.7             |1.4            |\n",
      "|1               |1.0              |1.0                 |5.6              |2.9             |3.6             |1.3            |\n",
      "|1               |1.0              |1.0                 |6.7              |3.1             |4.4             |1.4            |\n",
      "|1               |1.0              |1.0                 |5.6              |3.0             |4.5             |1.5            |\n",
      "|1               |1.0              |1.0                 |5.8              |2.7             |4.1             |1.0            |\n",
      "|1               |1.0              |1.0                 |6.2              |2.2             |4.5             |1.5            |\n",
      "|1               |1.0              |1.0                 |5.6              |2.5             |3.9             |1.1            |\n",
      "|1               |1.0              |1.0                 |5.9              |3.2             |4.8             |1.8            |\n",
      "|1               |1.0              |1.0                 |6.1              |2.8             |4.0             |1.3            |\n",
      "|1               |1.0              |2.0                 |6.3              |2.5             |4.9             |1.5            |\n",
      "|1               |1.0              |1.0                 |6.1              |2.8             |4.7             |1.2            |\n",
      "|1               |1.0              |1.0                 |6.4              |2.9             |4.3             |1.3            |\n",
      "|1               |1.0              |1.0                 |6.6              |3.0             |4.4             |1.4            |\n",
      "|1               |1.0              |1.0                 |6.8              |2.8             |4.8             |1.4            |\n",
      "|1               |2.0              |2.0                 |6.7              |3.0             |5.0             |1.7            |\n",
      "|1               |1.0              |1.0                 |6.0              |2.9             |4.5             |1.5            |\n",
      "|1               |1.0              |1.0                 |5.7              |2.6             |3.5             |1.0            |\n",
      "|1               |1.0              |1.0                 |5.5              |2.4             |3.8             |1.1            |\n",
      "|1               |1.0              |1.0                 |5.5              |2.4             |3.7             |1.0            |\n",
      "|1               |1.0              |1.0                 |5.8              |2.7             |3.9             |1.2            |\n",
      "|1               |1.0              |1.0                 |6.0              |2.7             |5.1             |1.6            |\n",
      "|1               |1.0              |1.0                 |5.4              |3.0             |4.5             |1.5            |\n",
      "|1               |1.0              |1.0                 |6.0              |3.4             |4.5             |1.6            |\n",
      "|1               |1.0              |1.0                 |6.7              |3.1             |4.7             |1.5            |\n",
      "|1               |1.0              |1.0                 |6.3              |2.3             |4.4             |1.3            |\n",
      "|1               |1.0              |1.0                 |5.6              |3.0             |4.1             |1.3            |\n",
      "|1               |1.0              |1.0                 |5.5              |2.5             |4.0             |1.3            |\n",
      "|1               |1.0              |1.0                 |5.5              |2.6             |4.4             |1.2            |\n",
      "|1               |1.0              |1.0                 |6.1              |3.0             |4.6             |1.4            |\n",
      "|1               |1.0              |1.0                 |5.8              |2.6             |4.0             |1.2            |\n",
      "|1               |1.0              |1.0                 |5.0              |2.3             |3.3             |1.0            |\n",
      "|1               |1.0              |1.0                 |5.6              |2.7             |4.2             |1.3            |\n",
      "|1               |1.0              |1.0                 |5.7              |3.0             |4.2             |1.2            |\n",
      "|1               |1.0              |1.0                 |5.7              |2.9             |4.2             |1.3            |\n",
      "|1               |1.0              |1.0                 |6.2              |2.9             |4.3             |1.3            |\n",
      "|1               |1.0              |1.0                 |5.1              |2.5             |3.0             |1.1            |\n",
      "|1               |1.0              |1.0                 |5.7              |2.8             |4.1             |1.3            |\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_snowpark_df = rf_session.sql(\"\"\"SELECT LABEL AS ACTUAL_LABEL, \n",
    "               predict_rf_iris_model(SEPTAL_LENGTH, SEPTAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH) as PRED_rf_LABEL,\n",
    "               predict_dtree_iris_model(SEPTAL_LENGTH, SEPTAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH) as PRED_dtree_LABEL,\n",
    "               SEPTAL_LENGTH, SEPTAL_WIDTH, PETAL_LENGTH, PETAL_WIDTH\n",
    "               FROM (iris_dataset) LIMIT 100\"\"\")\n",
    "predict_snowpark_df.show(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2b8e3-7e14-4a49-8ec3-35132f43ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_session.close()\n",
    "print('Finished!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256179af-2c6c-4cc4-a633-395019236439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
