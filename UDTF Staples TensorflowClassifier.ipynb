{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2e5c14-0def-4e33-93ee-972c2583ae9a",
   "metadata": {},
   "source": [
    "### Training a tensorflow Classification model on 1 million row training set using UDTF (user defined table function)\n",
    "### Steps Followed\n",
    "##### 1. Import Snowpark libraries\n",
    "##### 2. Connect to snowflake\n",
    "##### 3. Define model stage\n",
    "##### 4. Define output schema\n",
    "##### 5. Define UDTF and class for UDTF\n",
    "##### 6. Load data to snowpark dataframe\n",
    "##### 7. Define and build parameter dataframe with Epochs and Batch_Size\n",
    "##### 8. Combine data and parameter dataframes (Cross Join)\n",
    "##### 9. Train using the UDTF defined in step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9a2a7-c64d-4782-8c11-6651ed1c4a7d",
   "metadata": {},
   "source": [
    "#### 1. Import Snowpark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27eaa41-7742-4ca4-8eca-2f10afa56ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from snowflake.snowpark.functions import (\n",
    "    udtf,\n",
    "    col,\n",
    "    lit,\n",
    "    row_number,\n",
    "    table_function,\n",
    ")\n",
    "from snowflake.snowpark.types import (\n",
    "    Variant,\n",
    "    IntegerType,\n",
    "    BooleanType,\n",
    "    FloatType,\n",
    "    StringType,\n",
    "    DoubleType,\n",
    "    BooleanType,\n",
    "    DateType,\n",
    "    StructType,\n",
    "    StructField,\n",
    "    LongType,\n",
    "    DecimalType,\n",
    ")\n",
    "from functools import reduce\n",
    "from snowflake.snowpark.window import Window\n",
    "import json\n",
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f46c0e-7d0f-4e06-908c-971ae4fe1268",
   "metadata": {},
   "source": [
    "### 2. Connect to snowflake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "271820ea-6bbe-4550-a3de-70bc8ce2c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Database: \"BANK1_CRM_DB\"\n",
      "Current Schema: \"PUBLIC\"\n",
      "Current Warehouse: \"APP_WH\"\n",
      "Warehouse set up:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='APP_WH', state='STARTED', type='STANDARD', size='X-Small', min_cluster_count=1, max_cluster_count=1, started_clusters=1, running=0, queued=0, is_default='N', is_current='Y', auto_suspend=600, auto_resume='true', available=' 100', provisioning='0', quiescing='0', other='0', created_on=datetime.datetime(2022, 2, 27, 4, 51, 57, 85000, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>), resumed_on=datetime.datetime(2022, 12, 30, 21, 27, 7, 83000, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>), updated_on=datetime.datetime(2022, 12, 30, 21, 27, 7, 83000, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>), owner='SYSADMIN', comment='', enable_query_acceleration='false', query_acceleration_max_scale_factor=8, resource_monitor='null', actives=1, pendings=0, failed=0, suspended=0, uuid='1463550724', scaling_policy='STANDARD')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowflake_connection_cfg = open('cred.json')\n",
    "snowflake_connection_cfg = snowflake_connection_cfg.read()\n",
    "snowflake_connection_cfg = json.loads(snowflake_connection_cfg)\n",
    "\n",
    "'''\n",
    "APP_WH XS\n",
    "LAB_WH S\n",
    "HMWH M optimized warehouse\n",
    "DCR_MA_WH L\n",
    "BANK1_WH XL\n",
    "'''\n",
    "\n",
    "# Creating Snowpark Session\n",
    "staples_tf_session = Session.builder.configs(snowflake_connection_cfg).create()\n",
    "print('Current Database:', staples_tf_session.get_current_database())\n",
    "print('Current Schema:', staples_tf_session.get_current_schema())\n",
    "print('Current Warehouse:', staples_tf_session.get_current_warehouse())\n",
    "print(\"Warehouse set up:\")\n",
    "staples_tf_session.sql(\"show warehouses like 'APP_WH'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ffc01-218b-4695-b0f1-b798c53e1926",
   "metadata": {},
   "source": [
    "### 3. Define model stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44da87-c7c5-4cb3-8d10-ba39c7c2d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "staples_tf_session.sql(\n",
    "    \"\"\"\n",
    "create or replace stage udtfmodels\n",
    "\"\"\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131e95cc-5229-4a2a-ae72-1c53f50a3cc1",
   "metadata": {},
   "source": [
    "### 4. Define output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec5559e-59b8-4767-98e7-5d9391bb5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"EPOCH\", IntegerType()),\n",
    "        StructField(\"BATCH_SIZE\", IntegerType()),\n",
    "        StructField(\"Accuracy\", FloatType()),\n",
    "        StructField(\"Checkpoint\", StringType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1c980-5a2c-4686-a601-4505ed82d716",
   "metadata": {},
   "source": [
    "### 5. Define UDTF and class for UDTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b0f1669-afea-447b-82c0-18cd4d234d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package tensorflow in the local environment is 2.10.0, which does not fit the criteria for the requirement tensorflow. Your UDF might not work when the package version is different between the server and your local environment\n",
      "package dill is not installed in the local environmentYour UDF might not work when the package is installed on the server but not on your local environment.\n",
      "The version of package joblib in the local environment is 1.2.0, which does not fit the criteria for the requirement joblib. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "@udtf(\n",
    "    output_schema=schema,\n",
    "    input_types=[\n",
    "        IntegerType(),\n",
    "        IntegerType(),\n",
    "        DoubleType(),\n",
    "        DoubleType(),\n",
    "        DoubleType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        FloatType(),\n",
    "        IntegerType(),\n",
    "    ],\n",
    "    name=\"hyperparameter_staples_tf_tuning\",\n",
    "    session=staples_tf_session,\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@udtfmodels\",\n",
    "    packages=[\"snowflake-snowpark-python\", \"pandas\", \"scikit-learn\",\"tensorflow\",\"dill\",\"joblib\"],\n",
    "    replace=True,\n",
    ")\n",
    "class forecast:\n",
    "    #Initializes state for stateful processing of input partitions\n",
    "    def __init__(self):\n",
    "        self.EPOCH = None\n",
    "        self.BATCH_SIZE = None\n",
    "        self.RECENCY_DAY = []\n",
    "        self.FREQUENCY = []\n",
    "        self.MONETORY = []\n",
    "        self.RMF_SCORE = []\n",
    "        self.DOTCOM = []\n",
    "        self.REWARDS_ACCOUNT = []\n",
    "        self.FREQ_1 = []\n",
    "        self.FREQ_2 = []\n",
    "        self.FREQ_3 = []\n",
    "        self.FREQ_4 = []\n",
    "        self.FREQ_5 = []\n",
    "        self.FREQ_6 = []\n",
    "        self.FREQ_7 = []\n",
    "        self.FREQ_8 = []\n",
    "        self.FREQ_9 = []\n",
    "        self.FREQ_10 = []\n",
    "        self.FREQ_11 = []\n",
    "        self.FREQ_12 = []\n",
    "        self.CNT_PER_PDT = []\n",
    "        self.CNT_PER_PDT_SFC = []\n",
    "        self.CNT_PER_PDT_VFC = []\n",
    "        self.NO_DISCOUNT = []\n",
    "        self.DISCOUNT_PROMOTION = []\n",
    "        self.LABEL = []\n",
    "        self.processedFirstRow = False\n",
    "    # Processes each input row, returning a tabular value as tuples. Snowflake invokes this method, passing input from the UDTF's arguments.\n",
    "    def process(\n",
    "        self,\n",
    "        EPOCH,\n",
    "        BATCH_SIZE,\n",
    "        RECENCY_DAY,\n",
    "        FREQUENCY,\n",
    "        MONETORY,\n",
    "        RMF_SCORE,\n",
    "        DOTCOM,\n",
    "        REWARDS_ACCOUNT,\n",
    "        FREQ_1,\n",
    "        FREQ_2,\n",
    "        FREQ_3,\n",
    "        FREQ_4,\n",
    "        FREQ_5,\n",
    "        FREQ_6,\n",
    "        FREQ_7,\n",
    "        FREQ_8,\n",
    "        FREQ_9,\n",
    "        FREQ_10,\n",
    "        FREQ_11,\n",
    "        FREQ_12,\n",
    "        CNT_PER_PDT,\n",
    "        CNT_PER_PDT_SFC,\n",
    "        CNT_PER_PDT_VFC,\n",
    "        NO_DISCOUNT,\n",
    "        DISCOUNT_PROMOTION,\n",
    "        LABEL,\n",
    "    ):\n",
    "    # We are telling the UDTF only to run 288 models based on the unique combination of hyperparameters rather than every record in our data set.\n",
    "        if not self.processedFirstRow:\n",
    "            self.EPOCH = EPOCH\n",
    "            self.BATCH_SIZE = BATCH_SIZE\n",
    "            self.processedFirstRow = True\n",
    "        self.RECENCY_DAY.append(RECENCY_DAY)\n",
    "        self.FREQUENCY.append(FREQUENCY)\n",
    "        self.MONETORY.append(MONETORY)\n",
    "        self.RMF_SCORE.append(RMF_SCORE)\n",
    "        self.DOTCOM.append(DOTCOM)\n",
    "        self.REWARDS_ACCOUNT.append(REWARDS_ACCOUNT)\n",
    "        self.FREQ_1.append(FREQ_1)\n",
    "        self.FREQ_2.append(FREQ_2)\n",
    "        self.FREQ_3.append(FREQ_3)\n",
    "        self.FREQ_4.append(FREQ_4)\n",
    "        self.FREQ_5.append(FREQ_5)\n",
    "        self.FREQ_6.append(FREQ_6)\n",
    "        self.FREQ_7.append(FREQ_7)\n",
    "        self.FREQ_8.append(FREQ_8)\n",
    "        self.FREQ_9.append(FREQ_9)\n",
    "        self.FREQ_10.append(FREQ_10)\n",
    "        self.FREQ_11.append(FREQ_11)\n",
    "        self.FREQ_12.append(FREQ_12)\n",
    "        self.CNT_PER_PDT.append(CNT_PER_PDT)\n",
    "        self.CNT_PER_PDT_SFC.append(CNT_PER_PDT_SFC)\n",
    "        self.CNT_PER_PDT_VFC.append(CNT_PER_PDT_VFC)\n",
    "        self.NO_DISCOUNT.append(NO_DISCOUNT)\n",
    "        self.DISCOUNT_PROMOTION.append(DISCOUNT_PROMOTION)\n",
    "        self.LABEL.append(LABEL)\n",
    "\n",
    "    def end_partition(self):\n",
    "    # Finalizes processing of input partitions, returning a tabular value as tuples.\n",
    "    # Together the process is used to add the rows of a partition into the x1, x2 â€¦ lists, and then \n",
    "    # end_partition is called when all rows have been processed, and we then can train the model based on the hyperparameters in the first row\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            zip(self.RECENCY_DAY,self.FREQUENCY,self.MONETORY,self.RMF_SCORE,self.DOTCOM,self.REWARDS_ACCOUNT,self.FREQ_1,self.FREQ_2,self.FREQ_3,self.FREQ_4,self.FREQ_5,self.FREQ_6,self.FREQ_7,self.FREQ_8,self.FREQ_9,self.FREQ_10,self.FREQ_11,self.FREQ_12,self.CNT_PER_PDT,self.CNT_PER_PDT_SFC,self.CNT_PER_PDT_VFC,self.NO_DISCOUNT,self.DISCOUNT_PROMOTION,self.LABEL),\n",
    "            columns=[\"RECENCY_DAY\",\"FREQUENCY\",\"MONETORY\",\"RMF_SCORE\",\"DOTCOM\",\"REWARDS_ACCOUNT\",\"FREQ_1\",\"FREQ_2\",\"FREQ_3\",\"FREQ_4\",\"FREQ_5\",\"FREQ_6\",\"FREQ_7\",\"FREQ_8\",\"FREQ_9\",\"FREQ_10\",\"FREQ_11\",\"FREQ_12\",\"CNT_PER_PDT\",\"CNT_PER_PDT_SFC\",\"CNT_PER_PDT_VFC\",\"NO_DISCOUNT\",\"DISCOUNT_PROMOTION\",\"LABEL\"],\n",
    "            # zip(self.RECENCY_DAY,self.FREQUENCY,self.MONETORY,self.LABEL),\n",
    "            # columns=[\"RECENCY_DAY\",\"FREQUENCY\",\"MONETORY\",\"LABEL\"],\n",
    "\n",
    "        )\n",
    "\n",
    "        dfx = df.loc[:, df.columns != \"LABEL\"]\n",
    "        dfy = df.loc[:, df.columns == \"LABEL\"]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            dfx, dfy, test_size=0.25, random_state=43\n",
    "        )\n",
    "        import tensorflow as tf\n",
    "        import os\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "        from tensorflow.keras import datasets, layers, models\n",
    "        from tensorflow.keras import callbacks\n",
    "        \n",
    "        clf = Sequential()\n",
    "        clf.add(Dense(units = 10 , activation = 'relu'))\n",
    "        clf.add(Dropout(0.2))\n",
    "        clf.add(Dense(units = 1 , activation = 'sigmoid')) # Tanh\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "        clf.fit(X_train, y_train.values.ravel(), \n",
    "                       batch_size=self.BATCH_SIZE, \n",
    "                       epochs=self.EPOCH)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        score = clf.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "#         model_dir = '@udtfmodels'\n",
    "        \n",
    "#         model_file = os.path.join('/tmp',str(self.EPOCH), 'keras_model.h5')\n",
    "#         clf.save(model_file)\n",
    "        \n",
    "        filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "        checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')        \n",
    "        #session.file.put(checkpoint, modeldir,overwrite=True)\n",
    "\n",
    "        yield (\n",
    "            self.EPOCH,\n",
    "            self.BATCH_SIZE,\n",
    "            score[1], #adds accuracy to the training\n",
    "            str(checkpoint)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d980c-5300-40aa-935f-94ecf7acd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a339917-8178-4d7f-a1ea-d11cea6c90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"RECENCY_DAY\",\n",
    "\"FREQUENCY\",\n",
    "\"MONETORY\",\n",
    "\"RMF_SCORE\",\n",
    "\"DOTCOM\",\n",
    "\"REWARDS_ACCOUNT\",\n",
    "\"FREQ_1\",\n",
    "\"FREQ_2\",\n",
    "\"FREQ_3\",\n",
    "\"FREQ_4\",\n",
    "\"FREQ_5\",\n",
    "\"FREQ_6\",\n",
    "\"FREQ_7\",\n",
    "\"FREQ_8\",\n",
    "\"FREQ_9\",\n",
    "\"FREQ_10\",\n",
    "\"FREQ_11\",\n",
    "\"FREQ_12\",\n",
    "\"CNT_PER_PDT\",\n",
    "\"CNT_PER_PDT_SFC\",\n",
    "\"CNT_PER_PDT_VFC\",\n",
    "\"NO_DISCOUNT\",\n",
    "\"DISCOUNT_PROMOTION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff5e610-aea6-472f-ab0a-fb5a7103a0d8",
   "metadata": {},
   "source": [
    "### 6. Load data to snowpark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a98a14f5-63be-4889-b7ce-e20c5b14046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"RECENCY_DAY\"  |\"FREQUENCY\"  |\"MONETORY\"  |\"RMF_SCORE\"  |\"DOTCOM\"  |\"REWARDS_ACCOUNT\"  |\"FREQ_1\"  |\"FREQ_2\"  |\"FREQ_3\"  |\"FREQ_4\"  |\"FREQ_5\"  |\"FREQ_6\"  |\"FREQ_7\"  |\"FREQ_8\"  |\"FREQ_9\"  |\"FREQ_10\"  |\"FREQ_11\"  |\"FREQ_12\"  |\"CNT_PER_PDT\"  |\"CNT_PER_PDT_SFC\"  |\"CNT_PER_PDT_VFC\"  |\"NO_DISCOUNT\"  |\"DISCOUNT_PROMOTION\"  |\"LABEL\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|6.0            |2.0          |4.2         |2.833333333  |0.0       |1.0                |0.0       |0.0       |0.0       |6.0       |10.0      |1.0       |1.0       |1.0       |2.0       |0.0        |0.0        |0.0        |0.0            |0.0                |0.0                |26.0           |0.0                   |0        |\n",
      "|5.0            |1.0          |439.5       |3.0          |0.0       |1.0                |0.0       |1.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0        |0.0        |1.0        |0.0            |0.0                |0.0                |1.0            |0.0                   |1        |\n",
      "|284.0          |3.0          |43.98       |0.666666667  |0.0       |1.0                |0.0       |0.0       |0.0       |0.0       |0.0       |1.0       |0.0       |0.0       |0.0       |0.0        |0.0        |0.0        |0.0            |0.0                |0.0                |3.0            |0.0                   |0        |\n",
      "|287.0          |2.0          |151.96      |0.166666667  |0.0       |0.0                |2.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |1.0        |0.0        |0.0        |0.0            |0.0                |0.0                |4.0            |0.0                   |0        |\n",
      "|257.0          |25.0         |359.88      |0.833333333  |0.0       |0.0                |5.0       |25.0      |15.0      |10.0      |8.0       |5.0       |4.0       |8.0       |0.0       |14.0       |2.0        |0.0        |0.0            |0.0                |0.0                |89.0           |0.0                   |0        |\n",
      "|46.0           |7.0          |205.14      |2.083333333  |0.0       |1.0                |0.0       |0.0       |0.0       |0.0       |2.0       |0.0       |0.0       |0.0       |0.0       |1.0        |0.0        |3.0        |0.0            |0.0                |0.0                |7.0            |0.0                   |1        |\n",
      "|213.0          |9.0          |337.95      |0.833333333  |0.0       |1.0                |3.0       |6.0       |1.0       |3.0       |1.0       |4.0       |2.0       |2.0       |1.0       |7.0        |4.0        |0.0        |0.0            |0.0                |0.0                |41.0           |0.0                   |1        |\n",
      "|10.0           |1.0          |31.99       |3.0          |0.0       |1.0                |0.0       |1.0       |2.0       |3.0       |1.0       |0.0       |0.0       |2.0       |3.0       |1.0        |3.0        |1.0        |0.0            |0.0                |0.0                |22.0           |0.0                   |1        |\n",
      "|62.0           |10.0         |69.09       |2.666666667  |0.0       |1.0                |1.0       |0.0       |1.0       |5.0       |6.0       |5.0       |2.0       |0.0       |0.0       |0.0        |4.0        |3.0        |0.0            |0.0                |0.0                |45.0           |0.0                   |1        |\n",
      "|158.0          |1.0          |5.29        |0.333333333  |1.0       |0.0                |0.0       |0.0       |0.0       |0.0       |0.0       |8.0       |0.0       |0.0       |0.0       |0.0        |0.0        |0.0        |0.0            |0.0                |0.0                |4.0            |0.0                   |0        |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staples_tf_session.sql(\"use warehouse APP_WH\").collect()\n",
    "table_name = 'STAPLES_DATA_TRAIN_1M'\n",
    "features_df = staples_tf_session.table(table_name).select(*features,'LABEL')\n",
    "features_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baed205-51f9-4742-944a-d5035ec4f8c0",
   "metadata": {},
   "source": [
    "### 7. Define and build parameter dataframe with Epochs and Batch_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4080b483-68c0-4fa7-a4ba-50cec35a3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"EPOCH\": [x-(x-1) for x in range(1,201)],\n",
    "    \"BATCH_SIZE\": [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfe12179-4a48-4ebe-9991-8d7c035340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for k, v in param_grid.items():\n",
    "    df = pd.DataFrame(v, columns=[k])\n",
    "    dfs.append(df)\n",
    "\n",
    "df = reduce(lambda left, right: pd.merge(left, right, how=\"cross\"), dfs)\n",
    "params_df = staples_tf_session.createDataFrame(df)\n",
    "\n",
    "params_df = params_df.select(\n",
    "    \"*\", row_number().over(Window.order_by(lit(1))).as_(\"EPOCH#\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "182154b0-8dde-45c8-984a-352376f8f7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "|\"EPOCH\"  |\"BATCH_SIZE\"  |\"EPOCH#\"  |\n",
      "-------------------------------------\n",
      "|1        |100           |1         |\n",
      "|1        |100           |2         |\n",
      "|1        |100           |3         |\n",
      "|1        |100           |4         |\n",
      "|1        |100           |5         |\n",
      "|1        |100           |6         |\n",
      "|1        |100           |7         |\n",
      "|1        |100           |8         |\n",
      "|1        |100           |9         |\n",
      "|1        |100           |10        |\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af568dad-ff8b-4d47-aadf-b5bb7508ccd7",
   "metadata": {},
   "source": [
    "### 8. Combine data and parameter dataframes (Cross Join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c6b8961-2a25-4ba7-8e14-b5659f14ebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"EPOCH\"  |\"BATCH_SIZE\"  |\"EPOCH#\"  |\"RECENCY_DAY\"  |\"FREQUENCY\"  |\"MONETORY\"  |\"RMF_SCORE\"  |\"DOTCOM\"  |\"REWARDS_ACCOUNT\"  |\"FREQ_1\"  |\"FREQ_2\"  |\"FREQ_3\"  |\"FREQ_4\"  |\"FREQ_5\"  |\"FREQ_6\"  |\"FREQ_7\"  |\"FREQ_8\"  |\"FREQ_9\"  |\"FREQ_10\"  |\"FREQ_11\"  |\"FREQ_12\"  |\"CNT_PER_PDT\"  |\"CNT_PER_PDT_SFC\"  |\"CNT_PER_PDT_VFC\"  |\"NO_DISCOUNT\"  |\"DISCOUNT_PROMOTION\"  |\"LABEL\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1        |100           |22        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |23        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |24        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |25        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |26        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |27        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |28        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |29        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |30        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "|1        |100           |31        |21.0           |16.0         |420.137     |2.0          |0.0       |1.0                |9.0       |0.0       |9.0       |14.0      |9.0       |7.0       |7.0       |1.0       |7.0       |5.0        |3.0        |13.0       |5.0            |1.0                |0.0                |44.0           |2.0                   |0        |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = params_df.crossJoin(features_df)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b00f75-15bc-4c0f-b0db-56269d5b831f",
   "metadata": {},
   "source": [
    "### Use snowpark optimized warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6431e813-7234-44c4-a33d-659aa47792b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staples_tf_session.sql(\"use warehouse HMWH\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e8c65-3fe1-42dc-8c3a-08b2cde9d627",
   "metadata": {},
   "source": [
    "### 9. Train using the UDTF defined in step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0f450ea-e2ac-4c06-b492-03ec57f1e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "|\"EPOCH#\"  |\"ACCURACY\"          |\"CHECKPOINT\"                                        |\n",
      "--------------------------------------------------------------------------------------\n",
      "|13        |0.7091280221939087  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|32        |0.7064279913902283  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|87        |0.7064080238342285  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|78        |0.7058680057525635  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|72        |0.705839991569519   |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|86        |0.7058159708976746  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|25        |0.7057880163192749  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|24        |0.7057480216026306  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|99        |0.7055479884147644  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "|26        |0.7055040001869202  |<keras.callbacks.ModelCheckpoint object at 0xff...  |\n",
      "--------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_TUNING = table_function(\"hyperparameter_staples_tf_tuning\")\n",
    "tensorflow_training = df.select(\n",
    "    df[\"EPOCH#\"],\n",
    "    (\n",
    "        tf_TUNING(\n",
    "            df[\"EPOCH\"],\n",
    "            df[\"BATCH_SIZE\"],\n",
    "            df[\"RECENCY_DAY\"],\n",
    "            df[\"FREQUENCY\"],\n",
    "            df[\"MONETORY\"],\n",
    "            df[\"RMF_SCORE\"],\n",
    "            df[\"DOTCOM\"],\n",
    "            df[\"REWARDS_ACCOUNT\"],\n",
    "            df[\"FREQ_1\"],\n",
    "            df[\"FREQ_2\"],\n",
    "            df[\"FREQ_3\"],\n",
    "            df[\"FREQ_4\"],\n",
    "            df[\"FREQ_5\"],\n",
    "            df[\"FREQ_6\"],\n",
    "            df[\"FREQ_7\"],\n",
    "            df[\"FREQ_8\"],\n",
    "            df[\"FREQ_9\"],\n",
    "            df[\"FREQ_10\"],\n",
    "            df[\"FREQ_11\"],\n",
    "            df[\"FREQ_12\"],\n",
    "            df[\"CNT_PER_PDT\"],\n",
    "            df[\"CNT_PER_PDT_SFC\"],\n",
    "            df[\"CNT_PER_PDT_VFC\"],\n",
    "            df[\"NO_DISCOUNT\"],\n",
    "            df[\"DISCOUNT_PROMOTION\"],\n",
    "            df[\"LABEL\"]\n",
    "        ).over(partition_by=df[\"EPOCH#\"])\n",
    "    )\n",
    ").sort(col('Accuracy').desc())\n",
    "tensorflow_training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "872c4182-ce2f-406d-9c6f-89cece1591c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!!!\n"
     ]
    }
   ],
   "source": [
    "staples_tf_session.close()\n",
    "print('Finished!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5c3fb-7f78-4fb3-be6e-509b11755b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
